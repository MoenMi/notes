# 3 - Probability: Multivariate Models

## 3.1 - Joint distributions for multiple random variables

### 3.1.1 - Covariance



### 3.1.2 - Correlation



### 3.1.3 - Uncorrelated does not imply independent



### 3.1.4 - Correlation does not imply causation



### 3.1.5 - Simpsonâ€™s paradox



## 3.2 - The multivariate Gaussian (normal) distribution

### 3.2.1 - Definition



### 3.2.2 - Mahalanobis distance



### 3.2.3 - Marginals and conditionals of an MVN *



### 3.2.4 - Example: conditioning a 2d Gaussian



### 3.2.5 - Example: Imputing missing values *



## 3.3 - Linear Gaussian systems *

### 3.3.1 - Bayes rule for Gaussians



### 3.3.2 - Derivation *



### 3.3.3 - Example: Inferring an unknown scalar



### 3.3.4 - Example: inferring an unknown vector



### 3.3.5 - Example: sensor fusion



## 3.4 - The exponential family *

### 3.4.1 - Definition



### 3.4.2 - Example



### 3.4.3 - Log partition function is cumulant generating function



### 3.4.4 - Maximum entropy derivation of the exponential family



## 3.5 - Mixture models

### 3.5.1 - Gaussian mixture models



### 3.5.2 - Bernoulli mixture models



## 3.6 - Probabilistic graphical models *

### 3.6.1 - Representation



### 3.6.2 - Inference 



### 3.6.3 - Learning 



## 3.7 - Exercises
